{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **LLM Juge - RAG : April 2025**"
      ],
      "metadata": {
        "id": "1z1ewmbWgQTu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Wzr7jD7rp4V_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Making an LLM JUge to co;pare the quality of the answers given by a RAG.\n",
        "The RAg is based on GPT 4.o\n",
        "The Juge is based on Llama3\n"
      ],
      "metadata": {
        "id": "jt5V0B-7gbS0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import** **environmement**"
      ],
      "metadata": {
        "id": "B1xXwGF8g4qG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\" # Revenir à \"0\" plus tard\n",
        "os.environ['HF_HOME']=\"/work/LLM_models/HF_HOME\""
      ],
      "metadata": {
        "id": "rtFTtgVKg1vE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "D6Hnbk0rngK_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_community"
      ],
      "metadata": {
        "id": "sJanG7qVh6d3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ragatouille\n",
        "!pip install colbert"
      ],
      "metadata": {
        "id": "5Fbb4LEniRq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade transformers\n",
        "!pip install --upgrade ragatouille\n",
        "!pip install --upgrade colbert"
      ],
      "metadata": {
        "id": "Ku4x-zFljBxS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall colbert ragatouille -y\n",
        "!pip install ragatouille"
      ],
      "metadata": {
        "id": "Omo75F1qkdO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_community.chat_models import ChatOllama\n",
        "from langchain_community.embeddings import OllamaEmbeddings\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_community.embeddings.fastembed import FastEmbedEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
        "from langchain_community.embeddings.sentence_transformer import (\n",
        "    SentenceTransformerEmbeddings,\n",
        ")\n",
        "\n",
        "from langchain_community.document_loaders import BSHTMLLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_transformers import Html2TextTransformer\n",
        "from langchain.schema.runnable import RunnablePassthrough\n",
        "from langchain_core.runnables import RunnableParallel\n",
        "#===================================================================================================================\n",
        "# Message history management\n",
        "from langchain.chains import create_history_aware_retriever, create_retrieval_chain\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain_community.chat_message_histories import ChatMessageHistory\n",
        "from langchain_core.chat_history import BaseChatMessageHistory\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "#===================================================================================================================\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.vectorstores.utils import filter_complex_metadata\n",
        "\n",
        "#### ERROR ###\n",
        "#from ragatouille import RAGPretrainedModel\n",
        "#RAG.search(\"How many people live in France?\")\n",
        "\n",
        "from langchain_core.vectorstores import VectorStore\n",
        "from langchain_core.language_models.llms import LLM\n",
        "\n",
        "from tqdm import tqdm\n",
        "from glob import glob"
      ],
      "metadata": {
        "id": "ctj4YmmShHj8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LLM Juge : Llama3**"
      ],
      "metadata": {
        "id": "5aVMw2Mwme0A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " llama3_8b = ChatOllama(model=\"llama3:instruct\",\n",
        "                   base_url = \"http://10.179.0.20:5911\", # Pour aller interroger l'Ollama à distance (via GPU) / Plus besoin de faire le choix des GPU en début de notebook !?\n",
        "                   temperature=0.0) #local_llm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "tieAXXCymdq4",
        "outputId": "dad36571-8575-4339-adca-bb4f93d5757b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'ChatOllama' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-70c8d8908819>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m llama3_8b = ChatOllama(model=\"llama3:instruct\",\n\u001b[0m\u001b[1;32m      2\u001b[0m                   \u001b[0mbase_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"http://10.179.0.20:5911\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# Pour aller interroger l'Ollama à distance (via GPU) / Plus besoin de faire le choix des GPU en début de notebook !?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                   temperature=0.0) #local_llm\n",
            "\u001b[0;31mNameError\u001b[0m: name 'ChatOllama' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import QA Dataset**"
      ],
      "metadata": {
        "id": "v97d_ZN7nt2f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We extracted a sample of 500 questions asked by real users and aanswers generated by the RAG"
      ],
      "metadata": {
        "id": "Aqxrmx3VmDKQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "docs = pd.read_csv('Set_Questions_Reponses.csv')"
      ],
      "metadata": {
        "id": "sAIsNwhpnw_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setting up the vector store (Chunking & Embedding)"
      ],
      "metadata": {
        "id": "DxNMR_UL7M3p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=50) #, add_start_index=True, separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"],) # TODO: optimization\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=50,\n",
        "                add_start_index=True, separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"],)\n",
        "\n",
        "chunks = text_splitter.split_documents(docs_transformed)\n",
        "chunked_documents = filter_complex_metadata(chunks)"
      ],
      "metadata": {
        "id": "AqC-ONM37Ru0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Embedding # TODO: optimization\n",
        "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\") # Remarks: The all-mpnet-base-v2 model provides the best quality, while all-MiniLM-L6-v2 is 5 times faster and still offers good quality\n",
        "# embedding_function = FastEmbedEmbeddings()\n",
        "# embedding_function = SentenceTransformerEmbeddings(model_name=\"all-mpnet-base-v2\") # InvalidDimensionException: Embedding dimension 768 does not match collection dimensionality 384\n",
        "# # embedding_function = OllamaEmbeddings(model=\"nomic-embed-text\", base_url=\"http://10.6.10.10:5910\",) # avec Claudia en marche # Trop long : restart du kernel\n",
        "# # embedding_function = OllamaEmbeddings(model=\"nomic-embed-text\", base_url=\"http://10.6.10.26:5910\",) # nomic sur le batserver # Trop long : restart du kernel\n",
        "# # embedding_function = OllamaEmbeddings(model=\"nomic-embed-text\", base_url = \"http://10.179.0.20:5911\") # Trop long : restart du kernel\n",
        "# # embedding_function = OllamaEmbeddings(model=\"llama3:instruct\", base_url = \"http://10.179.0.20:5911\")  # Trop long : restart du kernel"
      ],
      "metadata": {
        "id": "2rqgJOWZ8A5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #==================================================================================================================================\n",
        "# #========= Tentative de résoudre le problème rencontré avec SentenceTransformerEmbeddings(model_name=\"all-mpnet-base-v2\") =========\n",
        "# #==================================================================================================================================\n",
        "# # import chromadb\n",
        "# # embedding_function = SentenceTransformerEmbeddings(model_name=\"all-mpnet-base-v2\")\n",
        "# # client = chromadb.PersistentClient(path='/work/sonarGPT/data/vectorStoreRep/chroma_db')\n",
        "# # collection = client.get_collection(name=\"langchain\", embedding_function=embedding_function) # ValueError: Expected EmbeddingFunction.__call__ to have the following signature: odict_keys(['self', 'input']), got odict_keys(['args', 'kwargs'])\n",
        "# #=================================================================================================================================="
      ],
      "metadata": {
        "id": "SZpYuV-68OD1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save the Chroma database to disk :\n",
        "vector_store_db_v0 = Chroma.from_documents(chunked_documents, embedding_function, persist_directory=\"/work/sonarGPT/data/vectorStoreRep/chroma_db\")\n",
        "vector_store_db_v0.persist()"
      ],
      "metadata": {
        "id": "Rp4O4Lb_8X0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"how do the wwc cooling system works?\"\n",
        "docs_test = vector_store_db_v0.similarity_search(query)\n",
        "print(docs_test[0].page_content)"
      ],
      "metadata": {
        "id": "0hOhTfLb8Y53"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the Chroma database from disk.\n",
        "vector_store_db = Chroma(persist_directory=\"/work/sonarGPT/data/vectorStoreRep/chroma_db\", embedding_function=embedding_function)"
      ],
      "metadata": {
        "id": "YDLQpJpY8e0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"how do the wwc cooling system works?\"\n",
        "docs_test = vector_store_db.similarity_search(query)\n",
        "print(docs_test[0].page_content)"
      ],
      "metadata": {
        "id": "Aau8XkAq8i9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting up the retriever"
      ],
      "metadata": {
        "id": "WJVNaqDq8qbx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vector_store_db.as_retriever()"
      ],
      "metadata": {
        "id": "Hu7BQiPW8ryh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(retriever))\n",
        "print(retriever)"
      ],
      "metadata": {
        "id": "wtP0qmFo8vYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "DPv4gtjzmpSq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Set Up critique agent**"
      ],
      "metadata": {
        "id": "4sDUM_N-mu4x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The questions can have many flaws. A quality check is done using critique agents that will rate each question on several criteria:\n",
        "- Groundedness: can the question be answered from the given context?\n",
        "- Relevance: is the question relevant to users?\n",
        "- Stand-alone: is the question understandable free of any context, for someone with domain knowledge?\n",
        "\n",
        "Each agent will received a score.\n",
        "Questions with score at any agent will be dropped of the evaluation dataset.\n",
        "\n",
        "When asking the agents to output a score, we first ask them to produce its rationale. This will help us verify scores, but most importantly, asking it to first output rationale gives the model more tokens to think and elaborate an answer before summarizing it into a single score token."
      ],
      "metadata": {
        "id": "Tj4E3k-dnFnw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question_groundedness_critique_prompt = \"\"\"\n",
        "You will be given a context and a question.\n",
        "Your task is to provide a 'total rating' scoring how well one can answer the given question unambiguously with the given context.\n",
        "Give your answer on a scale of 1 to 5, where 1 means that the question is not answerable at all given the context, and 5 means that the question is clearly and unambiguously answerable with the context.\n",
        "\n",
        "Provide your answer as follows:\n",
        "\n",
        "Answer:::\n",
        "Evaluation: (your rationale for the rating, as a text)\n",
        "Total rating: (your rating, as a number between 1 and 5)\n",
        "\n",
        "You MUST provide values for 'Evaluation:' and 'Total rating:' in your answer.\n",
        "\n",
        "Now here are the question and context.\n",
        "\n",
        "Question: {question}\\n\n",
        "Context: {context}\\n\n",
        "Answer::: \"\"\"\n",
        "\n",
        "question_relevance_critique_prompt = \"\"\"\n",
        "You will be given a question.\n",
        "Your task is to provide a 'total rating' representing how useful this question can be to a user specialized in writing commercial proposition who wishes to have answers about Thales and products developed by Thales.\n",
        "Give your answer on a scale of 1 to 5, where 1 means that the question is not useful at all, and 5 means that the question is extremely useful.\n",
        "\n",
        "Provide your answer as follows:\n",
        "\n",
        "Answer:::\n",
        "Evaluation: (your rationale for the rating, as a text)\n",
        "Total rating: (your rating, as a number between 1 and 5)\n",
        "\n",
        "You MUST provide values for 'Evaluation:' and 'Total rating:' in your answer.\n",
        "\n",
        "Now here is the question.\n",
        "\n",
        "Question: {question}\\n\n",
        "Answer::: \"\"\"\n",
        "\n",
        "question_standalone_critique_prompt = \"\"\"\n",
        "You will be given a question.\n",
        "Your task is to provide a 'total rating' representing how context-independant this question is.\n",
        "Give your answer on a scale of 1 to 5, where 1 means that the question depends on additional information to be understood, and 5 means that the question makes sense by itself.\n",
        "For instance, if the question refers to a particular setting, like 'in the context' or 'in the document', the rating must be 1.\n",
        "The questions can contain obscure technical nouns or acronyms like WCC, CfRx button, HCI  or TAHS and still be a 5: it must simply be clear to an operator with access to documentation what the question is about.\n",
        "\n",
        "Provide your answer as follows:\n",
        "\n",
        "Answer:::\n",
        "Evaluation: (your rationale for the rating, as a text)\n",
        "Total rating: (your rating, as a number between 1 and 5)\n",
        "\n",
        "You MUST provide values for 'Evaluation:' and 'Total rating:' in your answer.\n",
        "\n",
        "Now here is the question.\n",
        "\n",
        "Question: {question}\\n\n",
        "Answer::: \"\"\"\n"
      ],
      "metadata": {
        "id": "pHqJgogZo3S-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}